{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice, randint\n",
    "import gensim\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from pyemd import emd\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to generate logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_logs(sizelog1, sizelog2, averagesize, dictionarysize):\n",
    "    sentences1 = [\n",
    "    ['Act{}'.format(randint(1,dictionarysize)) for w in range(randint(averagesize-2,averagesize+2))]\n",
    "    for i in range(sizelog1)]\n",
    "    \n",
    "    sentences2 = [\n",
    "    ['Act{}'.format(randint(1,dictionarysize)) for w in range(randint(averagesize-2,averagesize+2))]\n",
    "    for i in range(sizelog2)]\n",
    "    \n",
    "    return(sentences1, sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logA, logB = generate_logs(1000, 1000, 20, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define wmd, ict and t2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WmDistance(object):\n",
    "    def __init__(self, wv, docset1, docset2):\n",
    "        self.wv = wv\n",
    "        self.docset1 = docset1\n",
    "        self.docset2 = docset2\n",
    "        self.dists = np.full((len(self.docset1), len(self.docset2)), np.nan)\n",
    "        self.dictionary = Dictionary(documents=self.docset1 + self.docset2)\n",
    "        self.vocab_len = len(self.dictionary)\n",
    "        self._cache_nbow()\n",
    "        self._cache_dmatrix()\n",
    "    def _cache_nbow(self):\n",
    "        self.nbow1 = [self._nbow(doc) for doc in self.docset1]\n",
    "        self.nbow2 = [self._nbow(doc) for doc in self.docset2]\n",
    "    def _nbow(self, document):\n",
    "        d = np.zeros(self.vocab_len, dtype=np.double)\n",
    "        nbow = self.dictionary.doc2bow(document)\n",
    "        doc_len = len(document)\n",
    "        for idx, freq in nbow:\n",
    "            d[idx] = freq / float(doc_len)\n",
    "        return d\n",
    "    def _cache_dmatrix(self):\n",
    "        self.distance_matrix = np.zeros((self.vocab_len, self.vocab_len), dtype=np.double)\n",
    "        for i, t1 in self.dictionary.items():\n",
    "            for j, t2 in self.dictionary.items():\n",
    "                if self.distance_matrix[i, j] != 0.0: continue\n",
    "                self.distance_matrix[i, j] = self.distance_matrix[j, i] = \\\n",
    "                    np.sqrt(np.sum((self.wv[t1] - self.wv[t2])**2))\n",
    "    def __getitem__(self, ij):\n",
    "        if np.isnan(self.dists[ij[0], ij[1]]):\n",
    "            self.dists[ij[0], ij[1]] = emd(self.nbow1[ij[0]], self.nbow2[ij[1]], self.distance_matrix)\n",
    "        return self.dists[ij[0], ij[1]]\n",
    "\n",
    "#p and q are given as nbow, so an array with voc size and count weights\n",
    "def ACT(p, q, C, k): #for now C is new every trace comparison, ADD LATER old used for the early stopping\n",
    "    t = 0\n",
    "    for i in range(0, len(p)):\n",
    "        pi = p[i] #the weight of the ith element in p trace\n",
    "        if pi == 0.: #if this activity is not actually in p pi will be zero\n",
    "            continue\n",
    "        dummy_s = np.argsort(C[i]) #have to change to only use the thing where q[j] != 0\n",
    "        s = np.ones(k, dtype=int)\n",
    "        it = 0\n",
    "        j = 0\n",
    "        while it<k and j<len(dummy_s):\n",
    "            if q[dummy_s[j]] != 0.:\n",
    "                s[it] = int(dummy_s[j])\n",
    "                it = it + 1\n",
    "            j = j+1\n",
    "        l = 0\n",
    "        while l<k and pi>0:\n",
    "            r = min(pi, q[s[l]])\n",
    "            pi = pi - r\n",
    "            t = t + r*C[i, s[l]] \n",
    "            l = l+1\n",
    "        if pi != 0:\n",
    "            t =  t + pi*C[i, s[l-1]]\n",
    "    return t\n",
    "\n",
    "class ICT(object):\n",
    "    def __init__(self, wv, docset1, docset2, k):\n",
    "        self.wv = wv\n",
    "        self.docset1 = docset1\n",
    "        self.docset2 = docset2\n",
    "        self.k = k\n",
    "        self.dists = np.full((len(self.docset1), len(self.docset2)), np.nan)\n",
    "        self.dictionary = Dictionary(documents=self.docset1 + self.docset2)\n",
    "        self.vocab_len = len(self.dictionary)\n",
    "        self._cache_nbow()\n",
    "        self._cache_dmatrix()\n",
    "    def _cache_nbow(self):\n",
    "        self.nbow1 = [self._nbow(doc) for doc in self.docset1]\n",
    "        self.nbow2 = [self._nbow(doc) for doc in self.docset2]\n",
    "    def _nbow(self, document):\n",
    "        d = np.zeros(self.vocab_len, dtype=np.double)\n",
    "        nbow = self.dictionary.doc2bow(document)\n",
    "        doc_len = len(document)\n",
    "        for idx, freq in nbow:\n",
    "            d[idx] = freq / float(doc_len)\n",
    "        return d\n",
    "    def _cache_dmatrix(self):\n",
    "        self.distance_matrix = np.zeros((self.vocab_len, self.vocab_len), dtype=np.double)\n",
    "        for i, t1 in self.dictionary.items():\n",
    "            for j, t2 in self.dictionary.items():\n",
    "                if self.distance_matrix[i, j] != 0.0: continue\n",
    "                self.distance_matrix[i, j] = self.distance_matrix[j, i] = \\\n",
    "                    np.sqrt(np.sum((self.wv[t1] - self.wv[t2])**2))\n",
    "    def __getitem__(self, ij):\n",
    "        if np.isnan(self.dists[ij[0], ij[1]]):\n",
    "            self.dists[ij[0], ij[1]] = ACT(self.nbow1[ij[0]], self.nbow2[ij[1]], self.distance_matrix, self.k)\n",
    "        return self.dists[ij[0], ij[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2v(log1, log2):\n",
    "    \n",
    "    \n",
    "    tags_GT_log = []\n",
    "    tags_pert_log = []\n",
    "    \n",
    "    for j in range(len(log1)):\n",
    "        ID = str()\n",
    "        for i in range(len(log1[j])):\n",
    "            ID = ID + log1[j][i].replace(\" \", \"\")\n",
    "        trace_id = [ID]\n",
    "        tags_GT_log.append(trace_id)\n",
    "        \n",
    "    for j in range(len(log2)):\n",
    "        ID = str()\n",
    "        for i in range(len(log2[j])):\n",
    "            ID = ID + log2[j][i].replace(\" \", \"\")\n",
    "        trace_id = [ID]\n",
    "        tags_pert_log.append(trace_id)\n",
    "        \n",
    "    bothlog = log1 + log2\n",
    "    taggedlog = []\n",
    "    \n",
    "    \n",
    "    for j in range(len(bothlog)):\n",
    "        eventlist = []\n",
    "        ID = str()\n",
    "        for i in range(len(bothlog[j])):\n",
    "            ID = ID + bothlog[j][i].replace(\" \", \"\")\n",
    "        trace_id = [ID]\n",
    "        td = TaggedDocument(bothlog[j], trace_id)\n",
    "        taggedlog.append(td)\n",
    "    \n",
    "\n",
    "    \n",
    "    #use a combination of both logs to train, but each variant only once\n",
    "    model = gensim.models.Doc2Vec(taggedlog, alpha=0.025, vector_size= 8, window=3,  min_count=1, dm = 0)\n",
    "    model.train(taggedlog, total_examples=len(taggedlog), epochs=100)\n",
    "    \n",
    "    print(\"Model training done\")\n",
    "    \n",
    "    def cosdis(trace1, trace2):\n",
    "        rep1 = model.docvecs[trace1[0]]\n",
    "        rep2 = model.docvecs[trace2[0]]\n",
    "        return spatial.distance.cosine(rep1, rep2)\n",
    "    \n",
    "    def distmatrix(GTlog, pertlog):\n",
    "        distances = np.full((len(pertlog),len(GTlog)), 100.0) #each trace of the perturbed log is a row and each column is a trace from GT\n",
    "        for i in range(len(pertlog)):\n",
    "            #if i % 50 == 0:\n",
    "                #print ('Now calculating trace number %s'%i)\n",
    "            for j in range(len(GTlog)):\n",
    "                distances[i][j] = cosdis(pertlog[i],GTlog[j])\n",
    "        return distances\n",
    "    \n",
    "    disM = distmatrix(tags_GT_log, tags_pert_log)\n",
    "    #print(disM)\n",
    "    \n",
    "    #precision = np.average(np.amin(disM, axis=1)) #average of the minima of each row = compare pert to GT\n",
    "    \n",
    "    #fitness = np.average(np.amin(disM, axis=0)) #aevrage of the minima of each column = compare GT to pert\n",
    "    \n",
    "    #print(np.amin(disM, axis=0))\n",
    "    \n",
    "    #return(precision, fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logA, logB = generate_logs(100, 100, 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training done\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t2v(logA, logB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9471b79ce3f4447a9ddd410cdcdf5ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 882 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = gensim.models.Word2Vec(logA + logB, min_count=1, size=8, window=3)\n",
    "\n",
    "dist_matrix2 = np.zeros((len(logA), len(logB)))\n",
    "\n",
    "wmcalc = WmDistance(model.wv, logA, logB)\n",
    "\n",
    "for i, first_sent in enumerate(tqdm(logA)):\n",
    "    for j, second_sent in enumerate(logB):\n",
    "        dist_matrix2[i,j] = wmcalc[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd5692faf7449b2a0b9baba0e5748f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = gensim.models.Word2Vec(logA + logB, min_count=1, size=8, window=3)\n",
    "\n",
    "dist_matrix3 = np.zeros((len(logA), len(logB)))\n",
    "\n",
    "wmcalc = ICT(model.wv, logA, logB, 3) #k=3\n",
    "\n",
    "for i, first_sent in enumerate(tqdm(logA)):\n",
    "    for j, second_sent in enumerate(logB):\n",
    "        dist_matrix3[i,j] = wmcalc[i, j]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
